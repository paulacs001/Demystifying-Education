{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1388,
   "id": "7fed346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#\n",
    "# Global parameters\n",
    "#\n",
    "#####################\n",
    "\n",
    "target_idx=0                                        #Index of Target variable\n",
    "cross_val=0                                         #Control Switch for CV\n",
    "norm_target=0                                       #Normalize target switch\n",
    "norm_features=0                                     #Normalize features switch\n",
    "prebinned = 1                                       #Control if the target are classes\n",
    "binning=1                                           #Control Switch for Bin Target\n",
    "bin_cnt=3                                           #If bin target, this sets number of classes\n",
    "feat_start=1                                        #Start column of features\n",
    "k_cnt=5                                             #Number of 'Top k' best ranked features to select, only applies for fs_types 1 and 3\n",
    "lv_filter=1                                         #Control switch for low variance filter on features\n",
    "feat_select= 0                                      #Control Switch for Feature Selection\n",
    "fs_type=3                                           #Feature Selection type (1=Stepwise Backwards Removal, 2=Wrapper Select, 3=Univariate Selection)\n",
    "\n",
    "\n",
    "#Set global model parameters\n",
    "rand_st=0                                           #Set Random State variable for randomizing splits on runs\n",
    "feat_eng = 1                             #IF 1, run all types of feature engineering and output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "id": "71c16a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "id": "2adba34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G3</th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>age</th>\n",
       "      <th>absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   G3  school  sex  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  ...  \\\n",
       "0   0       0    0        1        0        0     4     4     0     4  ...   \n",
       "1   0       0    0        1        0        1     1     1     0     2  ...   \n",
       "2   0       0    0        1        1        1     1     1     0     2  ...   \n",
       "3   1       0    0        1        0        1     4     2     1     3  ...   \n",
       "4   0       0    0        1        0        1     3     3     2     2  ...   \n",
       "\n",
       "   internet  romantic  famrel  freetime  goout  Dalc  Walc  health  age  \\\n",
       "0         0         0       3         2      3     0     0       2   18   \n",
       "1         1         0       4         2      2     0     0       2   17   \n",
       "2         1         0       3         2      1     1     2       2   15   \n",
       "3         1         1       2         1      1     0     0       4   15   \n",
       "4         0         0       3         2      1     0     1       4   16   \n",
       "\n",
       "   absences  \n",
       "0         6  \n",
       "1         4  \n",
       "2        10  \n",
       "3         2  \n",
       "4         4  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('categorical_dataset_ML1.csv').iloc[:, 1:]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a401c96",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff51c3",
   "metadata": {},
   "source": [
    "    - Walc and Dalc into 1\n",
    "    - merge 3 types of support\n",
    "    - socializing (ratio between freetime and going out)\n",
    "    \n",
    "    \n",
    "    - Medu and Mjob very related, maybe only keep Medu?\n",
    "    - Medu and Fedu very related. Keep only that of guardian?\n",
    "        - Or just keep Medu\n",
    "    - Make and average parent education\n",
    "    - Keep only guardian edu / job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "id": "fee1d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Average Alcohol ###########\n",
    "data = pd.read_csv('categorical_dataset_ML1.csv').iloc[:, 1:]\n",
    "\n",
    "Walc = data.pop('Walc')\n",
    "Dalc = data.pop('Dalc')\n",
    "\n",
    "Avg_alcohol = pd.DataFrame({'Alcohol': (Walc + Dalc) / 2})\n",
    "print(Avg_alcohol)\n",
    "\n",
    "data = pd.concat( [data, Avg_alcohol], axis = 1)\n",
    "\n",
    "# data.to_csv('modelling_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "id": "13d7969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######## Merge Support types --> # Support ###########\n",
    "# # For None -> 0 ; # For family -> 1 ; # For school -> 2 ; # For paid -> 3 ; # For +1 type of support ->4\n",
    "\n",
    "# support = []\n",
    "# schoolsup = data.pop('schoolsup')\n",
    "# famsup = data.pop('famsup')\n",
    "# paid = data.pop('paid')\n",
    "\n",
    "# for i in range(len(data)):\n",
    "#     num_support = schoolsup[i] + famsup[i] + paid[i]\n",
    "#     if num_support > 1:\n",
    "#         support.append('4')  \n",
    "#     elif num_support == 0:\n",
    "#         support.append('0')   \n",
    "#     else:\n",
    "#         if schoolsup[i] == 1:\n",
    "#             support.append('2')    \n",
    "#         elif famsup[i] == 1:\n",
    "#             support.append('1')   \n",
    "#         else:\n",
    "#             support.append('3') \n",
    "            \n",
    "# support = pd.DataFrame({'support': support})\n",
    "# data = pd.concat([data, support], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "id": "59fd13e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########## Socializing Ratio ###########\n",
    "# # goout/freetime\n",
    "# goout = data.pop('goout')\n",
    "# freetime = data.pop('freetime')\n",
    "# social = []\n",
    "# for i in range(len(freetime)):\n",
    "#     if freetime[i] == 0:\n",
    "#         social.append(0)\n",
    "#     else:\n",
    "#         social.append(goout[i]/freetime[i])\n",
    "        \n",
    "# social = pd.DataFrame({'Social': social})\n",
    "# data = pd.concat([data, social], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "id": "8c3b26e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########## Studying Ratio ###########\n",
    "# # studytime/freetime\n",
    "# studytime = data.pop('studytime')\n",
    "# freetime = data.pop('freetime')\n",
    "# study = []\n",
    "# for i in range(len(studytime)):\n",
    "#     if freetime[i] == 0:\n",
    "#         study.append(0)\n",
    "#     else:\n",
    "#         study.append(studytime[i]/freetime[i])\n",
    "        \n",
    "# study = pd.DataFrame({'Study': study})\n",
    "# data = pd.concat([data, study], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "id": "68e2ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########## Repeaters ###########\n",
    "# # if age > 16 and failures > 0\n",
    "# age = data.pop('age')\n",
    "# failures = data.pop('failures')\n",
    "\n",
    "# Repeater = []\n",
    "# for i in range(len(failures)):\n",
    "#     if age[i] > 16 and failures[i] > 0:\n",
    "#         Repeater.append(1)\n",
    "#     else:\n",
    "#         Repeater.append(0)\n",
    "        \n",
    "# rep = pd.DataFrame({'Repeater': Repeater})\n",
    "# data = pd.concat([data, rep], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd18a667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81677639",
   "metadata": {},
   "source": [
    "# Creating a Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "id": "e9430776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, chi2\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, scale\n",
    "\n",
    "\n",
    "#Handle annoying warnings\n",
    "import warnings, sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.ConvergenceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "id": "44f6b5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G3', 'school', 'sex', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'goout', 'health', 'age', 'absences', 'Alcohol', 'Study']\n",
      "395 395\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "#\n",
    "# Load Data\n",
    "#\n",
    "#####################\n",
    "       \n",
    "\n",
    "#Read data\n",
    "header = list(data.columns)\n",
    "target= data.G3\n",
    "data= data.iloc[: , 1: ]\n",
    "\n",
    "\n",
    "#Test Print\n",
    "print(header)\n",
    "print(len(target),len(data))\n",
    "'''for i in range(10):\n",
    "    print(target[i])\n",
    "    print(data[i])'''\n",
    "print('\\n')\n",
    "\n",
    "data_np=np.asarray(data)\n",
    "target_np=np.asarray(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "id": "0c0c1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#\n",
    "# Preprocess data\n",
    "#\n",
    "##########################################\n",
    "\n",
    "\n",
    "if norm_target==1:\n",
    "    #Target normalization for continuous values\n",
    "    target_np=scale(target_np)\n",
    "\n",
    "if norm_features==1:\n",
    "    #Feature normalization for continuous values\n",
    "    data_np=scale(data_np)\n",
    "\n",
    "if binning==1:\n",
    "    if prebinned == 0:\n",
    "        #Discretize Target variable with KBinsDiscretizer\n",
    "        enc = KBinsDiscretizer(n_bins=[bin_cnt], encode='ordinal', strategy='quantile')                         #Strategy here is important, quantile creating equal bins, but kmeans prob being more valid \"clusters\"\n",
    "        target_np_bin = enc.fit_transform(target_np.reshape(-1,1))\n",
    "\n",
    "        #Get Bin min/max\n",
    "        temp=[[] for x in range(bin_cnt+1)]\n",
    "        for i in range(len(target_np)):\n",
    "            for j in range(bin_cnt):\n",
    "                if target_np_bin[i]==j:\n",
    "                    temp[j].append(target_np[i])\n",
    "\n",
    "        for j in range(bin_cnt):\n",
    "            print('Bin', j, ':', min(temp[j]), max(temp[j]), len(temp[j]))\n",
    "        print('\\n')\n",
    "\n",
    "        #Convert Target array back to correct shape\n",
    "        target_np=np.ravel(target_np_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "id": "9642aef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--LOW VARIANCE FILTER ON-- \n",
      "\n",
      "Selected ['Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'failures', 'famrel', 'goout', 'health', 'age', 'absences', 'Alcohol']\n",
      "Features (total, selected): 28 12\n",
      "\n",
      "\n",
      "--FEATURE SELECTION ON-- \n",
      "\n",
      "Stepwise Recursive Backwards - Random Forest: \n",
      "[13  6 11 10 12  2  3  4  4  5  7  7  6  8  8  9  9 11 13 12 10  5  3  1\n",
      "  1  1  1  1]\n",
      "Selected ['health', 'age', 'absences', 'Alcohol', 'Study']\n",
      "Features (total/selected): 28 5\n",
      "\n",
      "\n",
      "Wrapper Select - Random Forest: \n",
      "Selected ['Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'failures', 'famrel', 'goout', 'health', 'age', 'absences', 'Alcohol', 'Study']\n",
      "Features (total/selected): 28 13\n",
      "\n",
      "\n",
      "Univariate Feature Selection - Chi2: \n",
      "Ranked Features\n",
      "0 absences : 99.38454293588747\n",
      "1 failures : 34.69088187928619\n",
      "2 Alcohol : 16.346640074935863\n",
      "3 Medu : 10.772454643187384\n",
      "4 schoolsup : 10.340600150767209\n",
      "5 traveltime : 8.444099041201081\n",
      "6 reason : 7.713171079906538\n",
      "7 romantic : 4.9502176929833\n",
      "8 Fedu : 3.844065596823003\n",
      "9 health : 3.4035991086423096\n",
      "10 Mjob : 3.269653350964612\n",
      "11 Study : 2.8209184410115475\n",
      "12 school : 2.5207021506471508\n",
      "13 goout : 1.718338568719482\n",
      "14 address : 1.5211302217919214\n",
      "15 sex : 1.4883275770127418\n",
      "16 age : 0.8551271037568701\n",
      "17 Fjob : 0.8322797114613107\n",
      "18 internet : 0.7268124868153\n",
      "19 activities : 0.6890045660723068\n",
      "20 guardian : 0.6744792401401856\n",
      "21 famrel : 0.6095330496566835\n",
      "22 nursery : 0.5334468777053093\n",
      "23 Pstatus : 0.3680464890448006\n",
      "24 higher : 0.3615819209039558\n",
      "25 famsize : 0.1437214885083729\n",
      "26 famsup : 0.10579317167313709\n",
      "27 paid : 0.021260351661480867\n",
      "\n",
      "\n",
      "Selected ['Medu', 'failures', 'schoolsup', 'absences', 'Alcohol']\n",
      "Features (total/selected): 28 5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "#\n",
    "# Feature Selection\n",
    "#\n",
    "##########################################\n",
    "\n",
    "#Low Variance Filter\n",
    "if lv_filter==1 or feat_eng == 1:\n",
    "    print('--LOW VARIANCE FILTER ON--', '\\n')\n",
    "    \n",
    "    #LV Threshold\n",
    "    sel = VarianceThreshold(threshold=0.5)                                      #Removes any feature with less than 20% variance\n",
    "    fit_mod=sel.fit(data_np)\n",
    "    fitted=sel.transform(data_np)\n",
    "    sel_idx=fit_mod.get_support()\n",
    "\n",
    "    #Get lists of selected and non-selected features (names and indexes)\n",
    "    temp=[]\n",
    "    temp_idx=[]\n",
    "    temp_del=[]\n",
    "    for i in range(len(data_np[0])):\n",
    "        if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "            temp.append(header[i+feat_start])\n",
    "            temp_idx.append(i)\n",
    "        else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "            temp_del.append(i)\n",
    "\n",
    "    print('Selected', temp)\n",
    "    print('Features (total, selected):', len(data_np[0]), len(temp))\n",
    "    print('\\n')\n",
    "\n",
    "    #Filter selected columns from original dataset\n",
    "    if feat_eng != 1:\n",
    "        header = header[0:feat_start]\n",
    "        for field in temp:\n",
    "            header.append(field)\n",
    "        data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index\n",
    "\n",
    "\n",
    "#Feature Selection\n",
    "if feat_select==1 or feat_eng == 1:\n",
    "    '''Three steps:\n",
    "       1) Run Feature Selection\n",
    "       2) Get lists of selected and non-selected features\n",
    "       3) Filter columns from original dataset\n",
    "       '''\n",
    "    \n",
    "    print('--FEATURE SELECTION ON--', '\\n')\n",
    "    \n",
    "    ##1) Run Feature Selection #######\n",
    "    if fs_type==1 or feat_eng == 1:\n",
    "        #Stepwise Recursive Backwards Feature removal\n",
    "        if binning==1:\n",
    "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=None)\n",
    "            sel = RFE(clf, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "        if binning==0:\n",
    "            rgr = RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=3, criterion='squared_error', random_state=None)\n",
    "            sel = RFE(rgr, n_features_to_select=k_cnt, step=.1)\n",
    "            print('Stepwise Recursive Backwards - Random Forest: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)\n",
    "        print(sel.ranking_)\n",
    "        sel_idx=fit_mod.get_support()      \n",
    "        \n",
    "\n",
    "        ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
    "        temp=[]\n",
    "        temp_idx=[]\n",
    "        temp_del=[]\n",
    "        for i in range(len(data_np[0])):\n",
    "            if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "                temp.append(header[i+feat_start])\n",
    "                temp_idx.append(i)\n",
    "            else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "                temp_del.append(i)\n",
    "        print('Selected', temp)\n",
    "        print('Features (total/selected):', len(data_np[0]), len(temp))\n",
    "        print('\\n')\n",
    "\n",
    "                \n",
    "    ##3) Filter selected columns from original dataset #########\n",
    "    if feat_eng != 1:\n",
    "        header = header[0:feat_start]\n",
    "        for field in temp:\n",
    "            header.append(field)\n",
    "        data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
    "\n",
    "    if fs_type==2 or feat_eng == 1:\n",
    "        #Wrapper Select via model\n",
    "        if binning==1:\n",
    "            clf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=3, criterion='entropy', random_state=None)\n",
    "            sel = SelectFromModel(clf, prefit=False, threshold='mean', max_features=None)                                                           #to select only based on max_features, set to integer value and set threshold=-np.inf\n",
    "            print ('Wrapper Select - Random Forest: ')\n",
    "        if binning==0:\n",
    "            rgr = RandomForestRegressor(n_estimators=500, max_features=.33, max_depth=None, min_samples_split=3, criterion='squared_error', random_state=None)\n",
    "            sel = SelectFromModel(rgr, prefit=False, threshold='mean', max_features=None)\n",
    "            print ('Wrapper Select - Random Forest: ')\n",
    "            \n",
    "        fit_mod=sel.fit(data_np, target_np)    \n",
    "        sel_idx=fit_mod.get_support()\n",
    "        \n",
    "        ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
    "        temp=[]\n",
    "        temp_idx=[]\n",
    "        temp_del=[]\n",
    "        for i in range(len(data_np[0])):\n",
    "            if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "                temp.append(header[i+feat_start])\n",
    "                temp_idx.append(i)\n",
    "            else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "                temp_del.append(i)\n",
    "        print('Selected', temp)\n",
    "        print('Features (total/selected):', len(data_np[0]), len(temp))\n",
    "        print('\\n')\n",
    "\n",
    "    if fs_type==3 or feat_eng == 1:       \n",
    "        if binning==1:                                                              ######Only work if the Target is binned###########\n",
    "            #Univariate Feature Selection - Chi-squared\n",
    "            sel=SelectKBest(chi2, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)                                         #will throw error if any negative values in features, so turn off feature normalization, or switch to mutual_info_classif\n",
    "            print ('Univariate Feature Selection - Chi2: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        if binning==0:                                                              ######Only work if the Target is continuous###########\n",
    "            #Univariate Feature Selection - Mutual Info Regression\n",
    "            sel=SelectKBest(mutual_info_regression, k=k_cnt)\n",
    "            fit_mod=sel.fit(data_np, target_np)\n",
    "            print ('Univariate Feature Selection - Mutual Info: ')\n",
    "            sel_idx=fit_mod.get_support()\n",
    "\n",
    "        #Print ranked variables out sorted\n",
    "        temp=[]\n",
    "        scores=fit_mod.scores_\n",
    "        for i in range(feat_start, len(header)):            \n",
    "            temp.append([header[i], float(scores[i-feat_start])])\n",
    "\n",
    "        print('Ranked Features')\n",
    "        temp_sort=sorted(temp, key=itemgetter(1), reverse=True)                     #Doesn't always sort correctly (e.g. for Chi Sq), so doublecheck output\n",
    "        for i in range(len(temp_sort)):\n",
    "            print(i, temp_sort[i][0], ':', temp_sort[i][1])\n",
    "        print('\\n')\n",
    "        \n",
    "        ##2) Get lists of selected and non-selected features (names and indexes) #######\n",
    "        temp=[]\n",
    "        temp_idx=[]\n",
    "        temp_del=[]\n",
    "        for i in range(len(data_np[0])):\n",
    "            if sel_idx[i]==1:                                                           #Selected Features get added to temp header\n",
    "                temp.append(header[i+feat_start])\n",
    "                temp_idx.append(i)\n",
    "            else:                                                                       #Indexes of non-selected features get added to delete array\n",
    "                temp_del.append(i)\n",
    "        print('Selected', temp)\n",
    "        print('Features (total/selected):', len(data_np[0]), len(temp))\n",
    "        print('\\n')\n",
    "    \n",
    "                \n",
    "    ##3) Filter selected columns from original dataset #########\n",
    "    if feat_eng != 1:\n",
    "        header = header[0:feat_start]\n",
    "        for field in temp:\n",
    "            header.append(field)\n",
    "        data_np = np.delete(data_np, temp_del, axis=1)                                 #Deletes non-selected features by index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a40dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8206e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95affc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
